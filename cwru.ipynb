{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwru.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/fboldt/algoritmos/blob/master/cwru.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Con6WhcSFxxm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CWRU files location"
      ]
    },
    {
      "metadata": {
        "id": "uSt7Dc1-nzQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aquisitions = {}\n",
        "# Normal\n",
        "aquisitions[\"Normal_0\"] = \"97.mat\"\n",
        "aquisitions[\"Normal_1\"] = \"98.mat\"\n",
        "aquisitions[\"Normal_2\"] = \"99.mat\"\n",
        "aquisitions[\"Normal_3\"] = \"100.mat\"\n",
        "# DE Inner Race 0.007 inches\n",
        "aquisitions[\"DEIR007_0\"] = \"105.mat\"\n",
        "aquisitions[\"DEIR007_1\"] = \"106.mat\"\n",
        "aquisitions[\"DEIR007_2\"] = \"107.mat\"\n",
        "aquisitions[\"DEIR007_3\"] = \"108.mat\"\n",
        "# DE Inner Race 0.014 inches\n",
        "aquisitions[\"DEIR014_0\"] = \"169.mat\"\n",
        "aquisitions[\"DEIR014_1\"] = \"170.mat\"\n",
        "aquisitions[\"DEIR014_2\"] = \"171.mat\"\n",
        "aquisitions[\"DEIR014_3\"] = \"172.mat\"\n",
        "# DE Inner Race 0.021 inches\n",
        "aquisitions[\"DEIR021_0\"] = \"209.mat\"\n",
        "aquisitions[\"DEIR021_1\"] = \"210.mat\"\n",
        "aquisitions[\"DEIR021_2\"] = \"211.mat\"\n",
        "aquisitions[\"DEIR021_3\"] = \"212.mat\"\n",
        "# DE Ball 0.007 inches\n",
        "aquisitions[\"DEB007_0\"] = \"118.mat\"\n",
        "aquisitions[\"DEB007_1\"] = \"119.mat\"\n",
        "aquisitions[\"DEB007_2\"] = \"120.mat\"\n",
        "aquisitions[\"DEB007_3\"] = \"121.mat\"\n",
        "# DE Ball 0.014 inches\n",
        "aquisitions[\"DEB014_0\"] = \"185.mat\"\n",
        "aquisitions[\"DEB014_1\"] = \"186.mat\"\n",
        "aquisitions[\"DEB014_2\"] = \"187.mat\"\n",
        "aquisitions[\"DEB014_3\"] = \"188.mat\"\n",
        "# DE Ball 0.021 inches\n",
        "aquisitions[\"DEB021_0\"] = \"222.mat\"\n",
        "aquisitions[\"DEB021_1\"] = \"223.mat\"\n",
        "aquisitions[\"DEB021_2\"] = \"224.mat\"\n",
        "aquisitions[\"DEB021_3\"] = \"225.mat\"\n",
        "# DE Outer race 0.007 inches centered @6:00\n",
        "aquisitions[\"DEOR007@6_0\"] = \"130.mat\"\n",
        "aquisitions[\"DEOR007@6_1\"] = \"131.mat\"\n",
        "aquisitions[\"DEOR007@6_2\"] = \"132.mat\"\n",
        "aquisitions[\"DEOR007@6_3\"] = \"133.mat\"\n",
        "# DE Outer race 0.014 inches centered @6:00\n",
        "aquisitions[\"DEOR014@6_0\"] = \"197.mat\"\n",
        "aquisitions[\"DEOR014@6_1\"] = \"198.mat\"\n",
        "aquisitions[\"DEOR014@6_2\"] = \"199.mat\"\n",
        "aquisitions[\"DEOR014@6_3\"] = \"200.mat\"\n",
        "# DE Outer race 0.021 inches centered @6:00\n",
        "aquisitions[\"DEOR021@6_0\"] = \"234.mat\"\n",
        "aquisitions[\"DEOR021@6_1\"] = \"235.mat\"\n",
        "aquisitions[\"DEOR021@6_2\"] = \"236.mat\"\n",
        "aquisitions[\"DEOR021@6_3\"] = \"237.mat\"\n",
        "# DE Outer race 0.007 inches centered @3:00\n",
        "aquisitions[\"DEOR007@3_0\"] = \"144.mat\"\n",
        "aquisitions[\"DEOR007@3_1\"] = \"145.mat\"\n",
        "aquisitions[\"DEOR007@3_2\"] = \"146.mat\"\n",
        "aquisitions[\"DEOR007@3_3\"] = \"147.mat\"\n",
        "# DE Outer race 0.021 inches centered @3:00\n",
        "aquisitions[\"DEOR021@3_0\"] = \"246.mat\"\n",
        "aquisitions[\"DEOR021@3_1\"] = \"247.mat\"\n",
        "aquisitions[\"DEOR021@3_2\"] = \"248.mat\"\n",
        "aquisitions[\"DEOR021@3_3\"] = \"249.mat\"\n",
        "# DE Outer race 0.007 inches centered @12:00\n",
        "aquisitions[\"DEOR007@12_0\"] = \"156.mat\"\n",
        "aquisitions[\"DEOR007@12_1\"] = \"158.mat\"\n",
        "aquisitions[\"DEOR007@12_2\"] = \"159.mat\"\n",
        "aquisitions[\"DEOR007@12_3\"] = \"160.mat\"\n",
        "# DE Outer race 0.021 inches centered @12:00\n",
        "aquisitions[\"DEOR021@12_0\"] = \"258.mat\"\n",
        "aquisitions[\"DEOR021@12_1\"] = \"259.mat\"\n",
        "aquisitions[\"DEOR021@12_2\"] = \"260.mat\"\n",
        "aquisitions[\"DEOR021@12_3\"] = \"261.mat\"\n",
        "# FE Inner Race 0.007 inches\n",
        "aquisitions[\"FEIR007_0\"] = \"278.mat\"\n",
        "aquisitions[\"FEIR007_1\"] = \"279.mat\"\n",
        "aquisitions[\"FEIR007_2\"] = \"280.mat\"\n",
        "aquisitions[\"FEIR007_3\"] = \"281.mat\"\n",
        "# FE Inner Race 0.014 inches\n",
        "aquisitions[\"FEIR014_0\"] = \"274.mat\"\n",
        "aquisitions[\"FEIR014_1\"] = \"275.mat\"\n",
        "aquisitions[\"FEIR014_2\"] = \"276.mat\"\n",
        "aquisitions[\"FEIR014_3\"] = \"277.mat\"\n",
        "# FE Inner Race 0.021 inches\n",
        "aquisitions[\"FEIR021_0\"] = \"270.mat\"\n",
        "aquisitions[\"FEIR021_1\"] = \"271.mat\"\n",
        "aquisitions[\"FEIR021_2\"] = \"272.mat\"\n",
        "aquisitions[\"FEIR021_3\"] = \"273.mat\"\n",
        "# FE Ball 0.007 inches\n",
        "aquisitions[\"FEB007_0\"] = \"282.mat\"\n",
        "aquisitions[\"FEB007_1\"] = \"283.mat\"\n",
        "aquisitions[\"FEB007_2\"] = \"284.mat\"\n",
        "aquisitions[\"FEB007_3\"] = \"285.mat\"\n",
        "# FE Ball 0.014 inches\n",
        "aquisitions[\"FEB014_0\"] = \"286.mat\"\n",
        "aquisitions[\"FEB014_1\"] = \"287.mat\"\n",
        "aquisitions[\"FEB014_2\"] = \"288.mat\"\n",
        "aquisitions[\"FEB014_3\"] = \"289.mat\"\n",
        "# FE Ball 0.021 inches\n",
        "aquisitions[\"FEB021_0\"] = \"290.mat\"\n",
        "aquisitions[\"FEB021_1\"] = \"291.mat\"\n",
        "aquisitions[\"FEB021_2\"] = \"292.mat\"\n",
        "aquisitions[\"FEB021_3\"] = \"293.mat\"\n",
        "# FE Outer race 0.007 inches centered @6:00\n",
        "aquisitions[\"FEOR007@6_0\"] = \"294.mat\"\n",
        "aquisitions[\"FEOR007@6_1\"] = \"295.mat\"\n",
        "aquisitions[\"FEOR007@6_2\"] = \"296.mat\"\n",
        "aquisitions[\"FEOR007@6_3\"] = \"297.mat\"\n",
        "# FE Outer race 0.007 inches centered @3:00\n",
        "aquisitions[\"FEOR007@3_0\"] = \"298.mat\"\n",
        "aquisitions[\"FEOR007@3_1\"] = \"299.mat\"\n",
        "aquisitions[\"FEOR007@3_2\"] = \"300.mat\"\n",
        "aquisitions[\"FEOR007@3_3\"] = \"301.mat\"\n",
        "# FE Outer race 0.014 inches centered @3:00\n",
        "aquisitions[\"FEOR014@3_0\"] = \"310.mat\"\n",
        "aquisitions[\"FEOR014@3_1\"] = \"309.mat\"\n",
        "aquisitions[\"FEOR014@3_2\"] = \"311.mat\"\n",
        "aquisitions[\"FEOR014@3_3\"] = \"312.mat\"\n",
        "# FE Outer race 0.007 inches centered @12:00\n",
        "aquisitions[\"FEOR007@12_0\"] = \"302.mat\"\n",
        "aquisitions[\"FEOR007@12_1\"] = \"305.mat\"\n",
        "aquisitions[\"FEOR007@12_2\"] = \"306.mat\"\n",
        "aquisitions[\"FEOR007@12_3\"] = \"307.mat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_4WiLNSyrMB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generate a dictionary linking the labels with values to keep consistence"
      ]
    },
    {
      "metadata": {
        "id": "zHDI4LWbyoP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_labels_dict(aquisitions):\n",
        "  labels_dict = {}\n",
        "  value = 0\n",
        "  for key in aquisitions.keys():\n",
        "    label = key.split('_')[0]\n",
        "    if not label in labels_dict:\n",
        "      labels_dict[label] = value\n",
        "      value += 1\n",
        "  return labels_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Rz0cKigF7q6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert Matlab file into tensors"
      ]
    },
    {
      "metadata": {
        "id": "2tn5IFqkCHQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "def aquisition2tensor(file_name, sample_size=512):\n",
        "  print(file_name, end=' ')\n",
        "  matlab_file = scipy.io.loadmat(file_name)\n",
        "  DE_time = [key for key in matlab_file if key.endswith(\"DE_time\")][0] #Find the DRIVE END aquisition key name\n",
        "  FE_time = [key for key in matlab_file if key.endswith(\"FE_time\")][0] #Find the FAN END aquisition key name\n",
        "  signal_begin = 0\n",
        "  aquisition_size = max(len(matlab_file[DE_time]),len(matlab_file[FE_time]))\n",
        "  DE_samples = []\n",
        "  FE_samples = []\n",
        "  while signal_begin + sample_size < aquisition_size:\n",
        "    DE_samples.append([item for sublist in matlab_file[DE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    FE_samples.append([item for sublist in matlab_file[FE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    signal_begin += sample_size\n",
        "  sample_tensor = np.stack([DE_samples,FE_samples],axis=2).astype('float32')\n",
        "  return sample_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-G4gjyuvA7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract datasets from aquisitions"
      ]
    },
    {
      "metadata": {
        "id": "YC4rhGwWMKT7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concatenate_datasets(xd,yd,xo,yo):\n",
        "  if xd is None or yd is None:\n",
        "    xd = xo\n",
        "    yd = yo\n",
        "  else:\n",
        "    xd = np.concatenate((xd,xo))\n",
        "    yd = np.concatenate((yd,yo))\n",
        "  return xd,yd\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "def aquisitions_from_load(load, aquisitions, labels_dict,\n",
        "                          url=\"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/\"\n",
        "                         ):\n",
        "  samples = None\n",
        "  labels = None\n",
        "  for key in aquisitions:\n",
        "    if key.endswith(\"_\"+str(load)):\n",
        "      file_name = aquisitions[key]\n",
        "      urllib.request.urlretrieve(url+file_name, file_name)\n",
        "      aquisition_samples = aquisition2tensor(file_name)\n",
        "      aquisition_labels = np.ones(aquisition_samples.shape[0])*labels_dict[key.split('_')[0]]\n",
        "      samples,labels = concatenate_datasets(samples,labels,aquisition_samples,aquisition_labels)\n",
        "  print(load)\n",
        "  return samples,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfwmQa0RJMvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Exrtract samples"
      ]
    },
    {
      "metadata": {
        "id": "HSASqQsHcgtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "98e1a809-db61-4468-f83a-cd1b67f507b3"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "labels_dict = get_labels_dict(aquisitions)\n",
        "print(labels_dict.keys())\n",
        "\n",
        "x0,y0 = aquisitions_from_load(0,aquisitions,labels_dict)\n",
        "x1,y1 = aquisitions_from_load(1,aquisitions,labels_dict)\n",
        "x2,y2 = aquisitions_from_load(2,aquisitions,labels_dict)\n",
        "x3,y3 = aquisitions_from_load(3,aquisitions,labels_dict)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['Normal', 'DEIR007', 'DEIR014', 'DEIR021', 'DEB007', 'DEB014', 'DEB021', 'DEOR007@6', 'DEOR014@6', 'DEOR021@6', 'DEOR007@3', 'DEOR021@3', 'DEOR007@12', 'DEOR021@12', 'FEIR007', 'FEIR014', 'FEIR021', 'FEB007', 'FEB014', 'FEB021', 'FEOR007@6', 'FEOR007@3', 'FEOR014@3', 'FEOR007@12'])\n",
            "97.mat 105.mat 169.mat 209.mat 118.mat 185.mat 222.mat 130.mat 197.mat 234.mat 144.mat 246.mat 156.mat 258.mat 278.mat 274.mat 270.mat 282.mat 286.mat 290.mat 294.mat 298.mat 310.mat 302.mat 0\n",
            "98.mat 106.mat 170.mat 210.mat 119.mat 186.mat 223.mat 131.mat 198.mat 235.mat 145.mat 247.mat 158.mat 259.mat 279.mat 275.mat 271.mat 283.mat 287.mat 291.mat 295.mat 299.mat 309.mat 305.mat 1\n",
            "99.mat 107.mat 171.mat 211.mat 120.mat 187.mat 224.mat 132.mat 199.mat 236.mat 146.mat 248.mat 159.mat 260.mat 280.mat 276.mat 272.mat 284.mat 288.mat 292.mat 296.mat 300.mat 311.mat 306.mat 2\n",
            "100.mat 108.mat 172.mat 212.mat 121.mat 188.mat 225.mat 133.mat 200.mat 237.mat 147.mat 249.mat 160.mat 261.mat 281.mat 277.mat 273.mat 285.mat 289.mat 293.mat 297.mat 301.mat 312.mat 307.mat 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_QgaHQFpBuDw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define f1-score macro averaged"
      ]
    },
    {
      "metadata": {
        "id": "HdRZ_4pJBzfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def f1_score_macro(y_true,y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPLjBiao2GIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define architecture model"
      ]
    },
    {
      "metadata": {
        "id": "fpcZrU4Mu9Vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "23a91f25-290a-4712-db7b-9a7ee264a603"
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "\n",
        "signal_input = Input(shape=(x0.shape[1],x0.shape[-1]), dtype='float32', name='signal')\n",
        "x = layers.Conv1D(64, 128, activation='relu')(signal_input)\n",
        "x = layers.Flatten()(x)\n",
        "condition_output = layers.Dense(len(labels_dict),activation='softmax',name='condition')(x)\n",
        "\n",
        "model = Model(signal_input, condition_output)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy',f1_score_macro])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "signal (InputLayer)          (None, 512, 2)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 385, 64)           16448     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 24640)             0         \n",
            "_________________________________________________________________\n",
            "condition (Dense)            (None, 24)                591384    \n",
            "=================================================================\n",
            "Total params: 607,832\n",
            "Trainable params: 607,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FfW63j1-6VgZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "'''\n",
        "history = model.fit(x_train,y_train,epochs=10,\n",
        "                    validation_split=0.33)#validation_data=(x_val,y_val))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1,len(loss_values)+1)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "epochs = range(1,len(acc_values)+1)\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "results = model.evaluate(x_test, y_test)\n",
        "results\n",
        "'''"
      ]
    },
    {
      "metadata": {
        "id": "y0xe9oYrW1lv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Perform experiments"
      ]
    },
    {
      "metadata": {
        "id": "UU0B-KF-W0eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9098
        },
        "outputId": "64f3e87e-c8ca-4f9c-bab4-b2fd4271dc0b"
      },
      "cell_type": "code",
      "source": [
        "loads = list(range(4))\n",
        "nrounds = 5\n",
        "results = []\n",
        "for i,fold in enumerate(loads):\n",
        "  print(fold)\n",
        "  x_test, y_test = eval('x'+str(fold)),eval('y'+str(fold))\n",
        "  y_test = to_categorical(y_test)\n",
        "  x_train,y_train = None,None\n",
        "  for tfold in loads[:i]+loads[i+1:]:\n",
        "    x_train,y_train = concatenate_datasets(x_train,y_train,eval('x'+str(tfold)),eval('y'+str(tfold)))\n",
        "  y_train = to_categorical(y_train)\n",
        "  print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
        "  for round in range(nrounds):\n",
        "    print(round+1)\n",
        "    history = model.fit(x_train,y_train,epochs=10,validation_split=0.33)\n",
        "    results.append(model.evaluate(x_test, y_test))\n",
        "    print(results[-1])\n",
        "  print(np.asarray(results[-nrounds:]))\n",
        "  print(np.mean(results[-nrounds:],axis=0),np.std(results[-nrounds:],axis=0))\n",
        "\n",
        "print(np.asarray(results))\n",
        "print(np.mean(results,axis=0),np.std(results,axis=0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(19208, 512, 2) (19208, 24) (5931, 512, 2) (5931, 24)\n",
            "1\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 7s 530us/step - loss: 0.0108 - acc: 0.8070 - f1_score_macro: 0.7912 - val_loss: 0.0028 - val_acc: 0.9598 - val_f1_score_macro: 0.9548\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 5s 354us/step - loss: 9.8281e-04 - acc: 0.9861 - f1_score_macro: 0.9869 - val_loss: 0.0013 - val_acc: 0.9820 - val_f1_score_macro: 0.9809\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 343us/step - loss: 1.5371e-04 - acc: 0.9981 - f1_score_macro: 0.9979 - val_loss: 0.0030 - val_acc: 0.9478 - val_f1_score_macro: 0.9469\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 5.8523e-05 - acc: 0.9992 - f1_score_macro: 0.9993 - val_loss: 6.8767e-04 - val_acc: 0.9891 - val_f1_score_macro: 0.9892\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 4.7393e-05 - acc: 0.9993 - f1_score_macro: 0.9993 - val_loss: 0.0010 - val_acc: 0.9839 - val_f1_score_macro: 0.9832\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 336us/step - loss: 4.0025e-05 - acc: 0.9994 - f1_score_macro: 0.9994 - val_loss: 6.4551e-04 - val_acc: 0.9907 - val_f1_score_macro: 0.9903\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 3.5096e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 5.5102e-04 - val_acc: 0.9913 - val_f1_score_macro: 0.9910\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.2961e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 0.0011 - val_acc: 0.9806 - val_f1_score_macro: 0.9809\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 3.2876e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 0.0026 - val_acc: 0.9550 - val_f1_score_macro: 0.9538\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 3.8442e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 5.5502e-04 - val_acc: 0.9924 - val_f1_score_macro: 0.9919\n",
            "5931/5931 [==============================] - 1s 157us/step\n",
            "[0.00366861250292258, 0.944697352941835, 0.9445013559562041]\n",
            "2\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 3.6858e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 6.2917e-04 - val_acc: 0.9910 - val_f1_score_macro: 0.9904\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.4014e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 4.8218e-04 - val_acc: 0.9923 - val_f1_score_macro: 0.9926\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 3.3718e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 5.1472e-04 - val_acc: 0.9927 - val_f1_score_macro: 0.9927\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.1629e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 8.8803e-04 - val_acc: 0.9866 - val_f1_score_macro: 0.9859\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.4022e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 5.8517e-04 - val_acc: 0.9910 - val_f1_score_macro: 0.9911\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 1.3620e-05 - acc: 0.9998 - f1_score_macro: 0.9998 - val_loss: 8.7074e-04 - val_acc: 0.9847 - val_f1_score_macro: 0.9850\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 3.3105e-06 - acc: 0.9999 - f1_score_macro: 0.9999 - val_loss: 4.3902e-04 - val_acc: 0.9931 - val_f1_score_macro: 0.9931\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 6.8056e-08 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 4.0149e-04 - val_acc: 0.9938 - val_f1_score_macro: 0.9937\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.4423e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 4.5014e-04 - val_acc: 0.9924 - val_f1_score_macro: 0.9923\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.0519e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 4.0756e-04 - val_acc: 0.9931 - val_f1_score_macro: 0.9932\n",
            "5931/5931 [==============================] - 1s 159us/step\n",
            "[0.003968365721204281, 0.9379531276847114, 0.9370804961184751]\n",
            "3\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 8.4647e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6523e-04 - val_acc: 0.9937 - val_f1_score_macro: 0.9937\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 7.4358e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.8986e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9936\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 6.6448e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.9751e-04 - val_acc: 0.9932 - val_f1_score_macro: 0.9933\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 6.1053e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.8228e-04 - val_acc: 0.9935 - val_f1_score_macro: 0.9936\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 5.6600e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.7066e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9935\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 5.2587e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4813e-04 - val_acc: 0.9937 - val_f1_score_macro: 0.9940\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 4.9745e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6449e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9935\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 4.7167e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.8939e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9934\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 4.4920e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4991e-04 - val_acc: 0.9937 - val_f1_score_macro: 0.9939\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 4.2780e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.5914e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9935\n",
            "5931/5931 [==============================] - 1s 161us/step\n",
            "[0.0037848686968616056, 0.9418310572075574, 0.9418438602269671]\n",
            "4\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 4.0926e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6012e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9937\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.9161e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4599e-04 - val_acc: 0.9937 - val_f1_score_macro: 0.9940\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.7715e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.7195e-04 - val_acc: 0.9935 - val_f1_score_macro: 0.9936\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 3.6435e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.1464e-04 - val_acc: 0.9946 - val_f1_score_macro: 0.9948\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.5705e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.7181e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9936\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.3925e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6645e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9936\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.2998e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.5882e-04 - val_acc: 0.9937 - val_f1_score_macro: 0.9938\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 345us/step - loss: 3.2032e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6227e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9934\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 347us/step - loss: 3.1136e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4538e-04 - val_acc: 0.9938 - val_f1_score_macro: 0.9941\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 349us/step - loss: 3.0306e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.5058e-04 - val_acc: 0.9937 - val_f1_score_macro: 0.9939\n",
            "5931/5931 [==============================] - 1s 167us/step\n",
            "[0.003689643186104441, 0.9440229304161226, 0.9438443508905537]\n",
            "5\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 341us/step - loss: 2.9473e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4807e-04 - val_acc: 0.9938 - val_f1_score_macro: 0.9939\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.8740e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.3742e-04 - val_acc: 0.9943 - val_f1_score_macro: 0.9944\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 2.8047e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.7218e-04 - val_acc: 0.9932 - val_f1_score_macro: 0.9933\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 2.7471e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6314e-04 - val_acc: 0.9932 - val_f1_score_macro: 0.9934\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 2.6766e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4082e-04 - val_acc: 0.9943 - val_f1_score_macro: 0.9944\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 2.6236e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4489e-04 - val_acc: 0.9942 - val_f1_score_macro: 0.9940\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.5566e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.5926e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9936\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 2.5108e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4937e-04 - val_acc: 0.9938 - val_f1_score_macro: 0.9940\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 2.4557e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.5585e-04 - val_acc: 0.9935 - val_f1_score_macro: 0.9936\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.4174e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.5263e-04 - val_acc: 0.9938 - val_f1_score_macro: 0.9938\n",
            "5931/5931 [==============================] - 1s 158us/step\n",
            "[0.0036772956514004125, 0.944697352941835, 0.943792603567024]\n",
            "[[0.00366861 0.94469735 0.94450136]\n",
            " [0.00396837 0.93795313 0.9370805 ]\n",
            " [0.00378487 0.94183106 0.94184386]\n",
            " [0.00368964 0.94402293 0.94384435]\n",
            " [0.0036773  0.94469735 0.9437926 ]]\n",
            "[0.00375776 0.94264036 0.94221253] [0.00011327 0.00256901 0.00271558]\n",
            "1\n",
            "(18739, 512, 2) (18739, 24) (6400, 512, 2) (6400, 24)\n",
            "1\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 2.5988e-04 - acc: 0.9957 - f1_score_macro: 0.9958 - val_loss: 0.0011 - val_acc: 0.9809 - val_f1_score_macro: 0.9816\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 3.5042e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 7.9360e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9867\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 3.2866e-06 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9699 - val_f1_score_macro: 0.9700\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 7.3088e-06 - acc: 0.9999 - f1_score_macro: 0.9999 - val_loss: 7.9889e-04 - val_acc: 0.9869 - val_f1_score_macro: 0.9867\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 7.5212e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.3157e-04 - val_acc: 0.9900 - val_f1_score_macro: 0.9902\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 2.5383e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8587e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9891\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 1.7823e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.3149e-04 - val_acc: 0.9906 - val_f1_score_macro: 0.9902\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 1.5864e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.7413e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9892\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 1.3458e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.3443e-04 - val_acc: 0.9880 - val_f1_score_macro: 0.9876\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.1799e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.5234e-04 - val_acc: 0.9898 - val_f1_score_macro: 0.9896\n",
            "6400/6400 [==============================] - 1s 156us/step\n",
            "[5.3620383637101014e-05, 0.99921875, 0.9992857140302658]\n",
            "2\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.0516e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1040e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9886\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 9.5545e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.7653e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9891\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 8.8238e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.4437e-04 - val_acc: 0.9901 - val_f1_score_macro: 0.9898\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 8.2187e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.6679e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9893\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 7.5319e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.6994e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 7.1065e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.3565e-04 - val_acc: 0.9901 - val_f1_score_macro: 0.9896\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 6.6729e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.3083e-04 - val_acc: 0.9901 - val_f1_score_macro: 0.9899\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 6.4422e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.3780e-04 - val_acc: 0.9900 - val_f1_score_macro: 0.9899\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 5.9753e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.4178e-04 - val_acc: 0.9900 - val_f1_score_macro: 0.9899\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 5.7728e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.1079e-04 - val_acc: 0.9903 - val_f1_score_macro: 0.9903\n",
            "6400/6400 [==============================] - 1s 159us/step\n",
            "[5.524664532188564e-05, 0.99921875, 0.9992857140302658]\n",
            "3\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 5.4944e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.1040e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9904\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 5.2209e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.1492e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9903\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 5.0306e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.1089e-04 - val_acc: 0.9906 - val_f1_score_macro: 0.9905\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 4.8669e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.1091e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9902\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 4.5939e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.0479e-04 - val_acc: 0.9909 - val_f1_score_macro: 0.9908\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 335us/step - loss: 4.4675e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.3431e-04 - val_acc: 0.9901 - val_f1_score_macro: 0.9901\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 4.3734e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.9943e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9905\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 4.2172e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.0385e-04 - val_acc: 0.9906 - val_f1_score_macro: 0.9905\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 4.0755e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.9290e-04 - val_acc: 0.9906 - val_f1_score_macro: 0.9906\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 3.9390e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.2889e-04 - val_acc: 0.9900 - val_f1_score_macro: 0.9898\n",
            "6400/6400 [==============================] - 1s 159us/step\n",
            "[5.5589337089358e-05, 0.99921875, 0.9992857140302658]\n",
            "4\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 3.8195e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.1510e-04 - val_acc: 0.9903 - val_f1_score_macro: 0.9903\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 3.7119e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.7767e-04 - val_acc: 0.9911 - val_f1_score_macro: 0.9912\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 3.6593e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.0133e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9907\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 3.4996e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.8190e-04 - val_acc: 0.9908 - val_f1_score_macro: 0.9909\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 3.4353e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.1081e-04 - val_acc: 0.9903 - val_f1_score_macro: 0.9903\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 3.3657e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.9865e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9905\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 3.3055e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.0714e-04 - val_acc: 0.9903 - val_f1_score_macro: 0.9903\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 3.2012e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.7273e-04 - val_acc: 0.9913 - val_f1_score_macro: 0.9914\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 3.1605e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.8994e-04 - val_acc: 0.9909 - val_f1_score_macro: 0.9909\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 336us/step - loss: 3.0526e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.8596e-04 - val_acc: 0.9908 - val_f1_score_macro: 0.9909\n",
            "6400/6400 [==============================] - 1s 159us/step\n",
            "[5.6120371614905255e-05, 0.99921875, 0.9992857140302658]\n",
            "5\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.9908e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.8857e-04 - val_acc: 0.9906 - val_f1_score_macro: 0.9908\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.9418e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.9168e-04 - val_acc: 0.9908 - val_f1_score_macro: 0.9910\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.8677e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.9098e-04 - val_acc: 0.9906 - val_f1_score_macro: 0.9908\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.8060e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.9632e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9908\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 2.7884e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.8603e-04 - val_acc: 0.9909 - val_f1_score_macro: 0.9909\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 2.7049e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.8263e-04 - val_acc: 0.9908 - val_f1_score_macro: 0.9912\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.6796e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.9508e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9906\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.6199e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.8564e-04 - val_acc: 0.9909 - val_f1_score_macro: 0.9910\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 2.5531e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.7995e-04 - val_acc: 0.9911 - val_f1_score_macro: 0.9911\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.5220e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 5.9686e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9906\n",
            "6400/6400 [==============================] - 1s 155us/step\n",
            "[5.5380110977114524e-05, 0.99921875, 0.9992857140302658]\n",
            "[[5.36203836e-05 9.99218750e-01 9.99285714e-01]\n",
            " [5.52466453e-05 9.99218750e-01 9.99285714e-01]\n",
            " [5.55893371e-05 9.99218750e-01 9.99285714e-01]\n",
            " [5.61203716e-05 9.99218750e-01 9.99285714e-01]\n",
            " [5.53801110e-05 9.99218750e-01 9.99285714e-01]]\n",
            "[5.51913697e-05 9.99218750e-01 9.99285714e-01] [8.40011723e-07 0.00000000e+00 0.00000000e+00]\n",
            "2\n",
            "(18736, 512, 2) (18736, 24) (6403, 512, 2) (6403, 24)\n",
            "1\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 2.9214e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 7.5013e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9877\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 2.6450e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 7.6904e-04 - val_acc: 0.9875 - val_f1_score_macro: 0.9876\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 3.9382e-06 - acc: 0.9999 - f1_score_macro: 0.9999 - val_loss: 7.8232e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9887\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 3.6603e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.4463e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9889\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.4140e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1675e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9878\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 9.3418e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.8185e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9884\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 8.5561e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9595e-04 - val_acc: 0.9879 - val_f1_score_macro: 0.9877\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 7.6302e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.5784e-04 - val_acc: 0.9879 - val_f1_score_macro: 0.9884\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 6.8735e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.4641e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9889\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 6.4504e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.5590e-04 - val_acc: 0.9880 - val_f1_score_macro: 0.9884\n",
            "6403/6403 [==============================] - 1s 165us/step\n",
            "[2.1763107948668413e-07, 1.0, 1.0]\n",
            "2\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 354us/step - loss: 6.0238e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.6083e-04 - val_acc: 0.9882 - val_f1_score_macro: 0.9884\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 5s 359us/step - loss: 5.2603e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.6259e-04 - val_acc: 0.9880 - val_f1_score_macro: 0.9885\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 5s 361us/step - loss: 5.1910e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.4226e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9887\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 4.8849e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.3483e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9888\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 4.6747e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8132e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9896\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 4.3955e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1425e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9891\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 4.1998e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2473e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9888\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 3.9243e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0996e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9896\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 3.8428e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0801e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9895\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 3.6509e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1353e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9891\n",
            "6403/6403 [==============================] - 1s 159us/step\n",
            "[1.6694753011152238e-07, 1.0, 1.0]\n",
            "3\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 3.5070e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2360e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9889\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 3.4347e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1638e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9890\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 3.3377e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8614e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9898\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 3.2404e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.3261e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9888\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 3.1642e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1357e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9894\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 3.0713e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9349e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9897\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 2.9908e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1215e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9892\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 2.9031e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0701e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9893\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 2.8518e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0346e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9894\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 2.7512e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1380e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9893\n",
            "6403/6403 [==============================] - 1s 157us/step\n",
            "[1.2325882978378838e-07, 1.0, 1.0]\n",
            "4\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 2.6748e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0269e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9892\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 2.6265e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0301e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9895\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 2.5510e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9881e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9894\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 2.5052e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1815e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9891\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 2.4735e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0172e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9896\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 2.4032e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1011e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9893\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 2.3441e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0557e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9893\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 2.3277e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9769e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9896\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 2.2724e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0902e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9892\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 2.2333e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9366e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9898\n",
            "6403/6403 [==============================] - 1s 162us/step\n",
            "[1.1267012006457106e-07, 1.0, 1.0]\n",
            "5\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 2.1840e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0961e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9893\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 2.1629e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9272e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9896\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 2.0882e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1722e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9892\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 2.0826e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0380e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9895\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 2.0448e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0430e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9894\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 2.0044e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9613e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9896\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 336us/step - loss: 1.9834e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0267e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9894\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 1.9442e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9643e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9895\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 336us/step - loss: 1.9292e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8896e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9896\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 1.8913e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0384e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9894\n",
            "6403/6403 [==============================] - 1s 158us/step\n",
            "[9.868299822025513e-08, 1.0, 1.0]\n",
            "[[2.17631079e-07 1.00000000e+00 1.00000000e+00]\n",
            " [1.66947530e-07 1.00000000e+00 1.00000000e+00]\n",
            " [1.23258830e-07 1.00000000e+00 1.00000000e+00]\n",
            " [1.12670120e-07 1.00000000e+00 1.00000000e+00]\n",
            " [9.86829982e-08 1.00000000e+00 1.00000000e+00]]\n",
            "[1.43838112e-07 1.00000000e+00 1.00000000e+00] [4.33898194e-08 0.00000000e+00 0.00000000e+00]\n",
            "3\n",
            "(18734, 512, 2) (18734, 24) (6405, 512, 2) (6405, 24)\n",
            "1\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.8509e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.0113e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 1.8133e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3233e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 1.7914e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.8926e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 1.7560e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.0290e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.7234e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9142e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 1.7122e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.7980e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.6931e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.6974e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.6625e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.0028e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.6607e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.4517e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.6288e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.7644e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 155us/step\n",
            "[0.0006588660128062565, 0.9896955503512881, 0.990020531290309]\n",
            "2\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 1.6139e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.8895e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 1.5932e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.5972e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 1.5693e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3111e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.5543e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2466e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 1.5271e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.7687e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 1.5104e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.6661e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 1.4747e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.6754e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.4672e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9186e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.4679e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0342e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 1.4435e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9601e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 157us/step\n",
            "[0.0006524974072636099, 0.9898516783762685, 0.9901715429754205]\n",
            "3\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.4213e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1576e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.4217e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.6642e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.4022e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.4670e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 1.3922e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.8851e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.3759e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.8507e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 1.3621e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9391e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.3485e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.7802e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.3357e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.6675e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 1.3209e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.6824e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 1.3133e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2106e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 159us/step\n",
            "[0.0006576851680676038, 0.9896955503512881, 0.9901715429754205]\n",
            "4\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.2975e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.5521e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.2893e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2994e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 350us/step - loss: 1.2760e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.4160e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 353us/step - loss: 1.2567e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0821e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 352us/step - loss: 1.2520e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1805e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 345us/step - loss: 1.2319e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0361e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 1.2306e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2832e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 1.2161e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2782e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.2076e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0075e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 1.1954e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9626e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 159us/step\n",
            "[0.0006467737693204438, 0.9895394223263075, 0.9900178934613957]\n",
            "5\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 1.1893e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1592e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.1768e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0411e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 1.1678e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9196e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.1557e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2519e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 1.1481e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9754e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.1408e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.7328e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 1.1265e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1899e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 1.1216e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.6152e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 334us/step - loss: 1.1129e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9105e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 335us/step - loss: 1.1046e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.7729e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 159us/step\n",
            "[0.0006455592457284412, 0.9895394223263075, 0.9901071094331287]\n",
            "[[6.58866013e-04 9.89695550e-01 9.90020531e-01]\n",
            " [6.52497407e-04 9.89851678e-01 9.90171543e-01]\n",
            " [6.57685168e-04 9.89695550e-01 9.90171543e-01]\n",
            " [6.46773769e-04 9.89539422e-01 9.90017893e-01]\n",
            " [6.45559246e-04 9.89539422e-01 9.90107109e-01]]\n",
            "[6.52276321e-04 9.89664325e-01 9.90097724e-01] [5.44289847e-06 1.16835516e-04 6.82908456e-05]\n",
            "[[3.66861250e-03 9.44697353e-01 9.44501356e-01]\n",
            " [3.96836572e-03 9.37953128e-01 9.37080496e-01]\n",
            " [3.78486870e-03 9.41831057e-01 9.41843860e-01]\n",
            " [3.68964319e-03 9.44022930e-01 9.43844351e-01]\n",
            " [3.67729565e-03 9.44697353e-01 9.43792604e-01]\n",
            " [5.36203836e-05 9.99218750e-01 9.99285714e-01]\n",
            " [5.52466453e-05 9.99218750e-01 9.99285714e-01]\n",
            " [5.55893371e-05 9.99218750e-01 9.99285714e-01]\n",
            " [5.61203716e-05 9.99218750e-01 9.99285714e-01]\n",
            " [5.53801110e-05 9.99218750e-01 9.99285714e-01]\n",
            " [2.17631079e-07 1.00000000e+00 1.00000000e+00]\n",
            " [1.66947530e-07 1.00000000e+00 1.00000000e+00]\n",
            " [1.23258830e-07 1.00000000e+00 1.00000000e+00]\n",
            " [1.12670120e-07 1.00000000e+00 1.00000000e+00]\n",
            " [9.86829982e-08 1.00000000e+00 1.00000000e+00]\n",
            " [6.58866013e-04 9.89695550e-01 9.90020531e-01]\n",
            " [6.52497407e-04 9.89851678e-01 9.90171543e-01]\n",
            " [6.57685168e-04 9.89695550e-01 9.90171543e-01]\n",
            " [6.46773769e-04 9.89539422e-01 9.90017893e-01]\n",
            " [6.45559246e-04 9.89539422e-01 9.90107109e-01]]\n",
            "[0.00111634 0.98288086 0.98289899] [0.00154736 0.02362159 0.0238514 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tv7O1HexF8Ct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "np.savetxt(\"results.csv\", np.asarray(results), delimiter=\", \", newline=\"\\r\\n\")\n",
        "files.download('results.csv') \n",
        "np.savetxt(\"summary.csv\", np.asarray(np.asarray([np.mean(results,axis=0),np.std(results,axis=0)])), delimiter=\", \", newline=\"\\r\\n\")\n",
        "files.download('summary.csv') \n",
        "with open('model.txt','w') as fh:\n",
        "    model.summary(print_fn=lambda x: fh.write(x + '\\r\\n'))\n",
        "files.download('model.txt') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}